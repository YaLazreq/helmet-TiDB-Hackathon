import os
import sys

from tidb_vector.integrations import TiDBVectorClient
from sentence_transformers import SentenceTransformer
from dotenv import load_dotenv

sys.path.append("./src")  # Adjust the path as necessary to import from src
from config import Config

config = Config()

# Step 1. Initialize embedding model

print("Downloading and loading the embedding model...")
embed_model = SentenceTransformer(
    "sentence-transformers/msmarco-MiniLM-L12-cos-v5", trust_remote_code=True
)
embed_model_dims = embed_model.get_sentence_embedding_dimension()


def text_to_embedding(text):
    """Generates vector embeddings for the given text."""
    embedding = embed_model.encode(text)
    return embedding.tolist()


# Step 2. Initialize TiDBVectorClient instance

load_dotenv()

vector_store = TiDBVectorClient(
    # The table which will store the vector data.
    table_name="places",
    # The connection string to the TiDB cluster.
    # The connection string should be in the format of:
    connection_string=os.getenv("TIDB_CONNECTION_STRING"),
    # The dimension of the vector generated by the embedding model.
    vector_dimension=embed_model_dims,
    # Determine whether to recreate the table if it already exists.
    drop_existing_table=True,
)

# Step 3. Bulk insert objects and their embeddings

documents = [
    {
        "id": "f8e7dee2-63b6-42f1-8b60-2d46710c1971",
        "name": "Hôtel Plaza Athénée - Dorchester Collection",
        "embedding": text_to_embedding("dog"),
        "metadata": {"category": "animal"},
    },
    {
        "id": "8dde1fbc-2522-4ca2-aedf-5dcb2966d1c6",
        "name": "fish",
        "embedding": text_to_embedding("fish"),
        "metadata": {"category": "animal"},
    },
    {
        "id": "e4991349-d00b-485c-a481-f61695f2b5ae",
        "name": "tree",
        "embedding": text_to_embedding("tree"),
        "metadata": {"category": "plant"},
    },
]

vector_store.insert(
    ids=[doc["id"] for doc in documents],
    names=[doc["name"] for doc in documents],
    embeddings=[doc["embedding"] for doc in documents],
    metadatas=[doc["metadata"] for doc in documents],
)

# Step 4. Perform vector search to find the most semantically similar documents to the query.


def print_result(query, result):
    print(f'Search result ("{query}"):')
    for r in result:
        print(f'- text: "{r.document}", distance: {r.distance}')


query = "Hotel that organizes anniversary"
query_embedding = text_to_embedding(query)
search_result = vector_store.query(query_embedding, k=3)
print_result(query, search_result)
